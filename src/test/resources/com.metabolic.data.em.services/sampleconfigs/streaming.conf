{
    name: "Customers"
    engineMode = "Stream"
    sources: [
        {
            format = "kafka"
            name = "factorial_clean_companies"
            kafkaSecret = "production/kafka_credentials"
            topic = "factorial_clean_companies"
        },
        {
            format = "kafka"
            name = "factorial_clean_employees"
            kafkaSecret = "production/kafka_credentials"
            topic = "factorial_clean_employees"
            op.filter = {
                onColumn = "updated_at"
                    from = ${df.start_of_yesterday}
                    to = ${df.now}
            }
            op.dedupe = {
                idColumns = ["id"]
                orderColumns = ["yyyy","mm","dd","updated_at", "extracted_at"]
            }
        }
#         source.kafka {
#             name = "factorial_clean_employees"
#             server = "kafka:9092"
#             topic = "factorial_clean_employees"
#         }
#           source.parquet {
#                name = "factorial_clean_employees"
#                path = "s3://demo"
#           }
    ]
    mapping {
        sql = "SELECT * FROM factorial_clean_companies AS c JOIN factorial_clean_employees AS e ON e.company_id = c.id"
    }
    sink {
        format = "kafka"
        name = "factorial_gold_employees"
        kafkaSecret = "production/kafka_credentials"
        checkpointLocation = "./checkpointLocation"
        topic = "factorial_gold_employees"
    }
#       sink.kafka {
#           name = "factorial_gold_employees"
#           servers = "kafka:9092"
#           topic = "factorial_gold_employees"
#       }
#         sink.json {
#             name = "factorial_gold_employees"
#             path = "s3://ausias/ausias.json"
#         }
#         sink.delta {
#               name = "factorial_gold_employees"
#               path = "s3://ausias/"
#               idColumn = "id"
#               dateColumn = "updated_at"
#         }
}